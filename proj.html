<!DOCTYPE html>
<title>Bangya | Project</title>
<meta charset="UTF-8" />
<script src="https://unpkg.com/htmlincludejs"></script>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="preconnect" href="https://fonts.gstatic.com" />
<link
  rel="stylesheet"
  href="https://fonts.googleapis.com/css2?family=Noto+Serif+JP:wght@400;700&family=Noto+Serif+SC:wght@400;700&display=swap"/>
<link rel="stylesheet" href="css/styles.css" />

<!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v3.9.0" />
<!--
<meta name="description" content="desc" />
<meta property="og:title" content="title" />
<meta property="og:description" content="desc" />
<meta property="og:site_name" content="site_name" />
-->
<link rel="canonical" href="/" />
<meta property="og:url" content="/" />


<main>
<include src="include/nav.inc"></include>
<article class="">
    <h1>Project Highlight</h1>
    <div class="content">
        <p><b>ByteLOOM: Weaving Geometry-Consistent Human-Object Interactions through Curriculum Learning</b> (ByteDance Internship)<br/>
            <i>Keywords: HOI, DiT, 3D Reconstruction, Wan2.1</i><br/>
            Developed a human-object interaction video generation model based on Wan2.1 featuring realistic human dynamics and diverse object viewpoint synthesis. Addressed human-object dataset scarcity by curating large-scale open-source hand-object interaction datasets to train the DiT. To enhance controllability and geometric fidelity, introduced a novel geometry-aware conditioning mechanism combining multi-view object reference images with relative coordinate maps to support consistent generation across diverse viewpoints.<br/>
            <a href="https://neutrinoliu.github.io/byteloom/" target="_blank">https://neutrinoliu.github.io/byteloom/</a>
        </p>

        <p><b>SwinGS: Sliding Window Gaussian Splatting for Volumetric Video Streaming with Arbitrary Length</b><br/>
            <i>Keywords: Gaussian Splatting, Volumetric Video</i><br/>
            Proposed SwinGS, a novel framework for training, delivering, and rendering volumetric video in real-time streaming fashion. To address challenges including excessive model sizes, constraints on video duration, and content deviation, integrated spacetime Gaussian with Markov Chain Monte Carlo to adapt the model across various 3D scenes and frames. Employed a sliding window to capture Gaussian snapshots for each frame in a continuous training approach.<br/>
            <a href="https://swingsplat.github.io/demo/" target="_blank">https://swingsplat.github.io/demo/</a>
        </p>

        <p><b>Privacy-Aware Sharing of Raw Spatial Sensor Data for Cooperative Perception</b><br/>
            <i>Keywords: V2V, Cooperative Perception</i><br/>
            Addressed critical privacy challenges in deploying cooperative perception systems in untrusted real-world environments. First, demonstrated how vision foundation models like VGGT enable real-time dense reconstruction of road environments. Further, to preserve sharer anonymity, proposed a novel approach that generates synthetic yet semantically meaningful perception data at obfuscated locations, addressing the fundamental privacy concern of sharing geolocation data with perception information.
        </p>

        <p><b>MachSim: a Speedy and Scalable Flow Simulator for Traffic Distribution Prediction in Datacenter Network</b> (ByteDance Internship)<br/>
            <i>Keywords: Traffic Simulator, Datacenter Network, Scalability</i><br/>
            Designed, implemented, and evaluated a scalable flow simulator for datacenter networks. The simulator models traffic distribution by taking network topology, forwarding rules, and flow information as inputs. Leveraging optimization techniques including flow as directed acyclic graph and local flow merging, together with multiprocessing, MachSim achieves high efficiency, simulating 500K flows across 100 switches in 15 seconds. Integrated into ByteDance network infrastructure to verify configuration updates before production deployment.
        </p>

        <p><b>Sustainable Spectrum Crowdsensing</b><br/>
            <i>Keywords: Federated Learning, Blockchain, Spectrum Sensing</i><br/>
            Designed and implemented an asynchronous federated learning framework for large-scale spectrum sensing in a crowdsourcing manner, running on Android devices and SDR FPGA boards. Leveraged federated learning to address user privacy and data sharing challenges. Distributed the aggregation server with blockchain to enhance system robustness and facilitate reward schemes.<br/>
            <a href="https://fiesta4spectrum.github.io" target="_blank">https://fiesta4spectrum.github.io</a>
        </p>

        <p><b>Rocket-Chip FPGA Transplant</b><br/>
            <i>Keywords: FPGA, RISC-V</i><br/>
            Implemented a Verilog wrapper for the Rocket-Chip project and a Linux boot flow on Digilent Nexys4DDR. Provided the research community with an accessible platform enabling computer architects to boot Linux and perform evaluations on a RISC-V core using an affordable FPGA board instead of pure simulators. Project received 137 stars and 29 forks on GitHub.<br/>
            <a href="https://github.com/cnrv/fpga-rocket-chip" target="_blank">https://github.com/cnrv/fpga-rocket-chip</a>
        </p>

    </div>
</article>
<include src="include/aside.inc"></include>
</main>
